{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04dabfb0-a4eb-4612-b168-bbdfad531716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbfa287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.transforms.input import Normalize, InputStandardize\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.fit import fit_gpytorch_mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb7bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# training yaml file setup\n",
    "config1 = yaml.safe_load(open(\"20220806_two_bunch_FEL_with_kicker_2.yaml\"))\n",
    "data1 = pd.DataFrame(config1['data'])\n",
    "data1.index = map(int, data1.index)\n",
    "data1 = data1.sort_index(axis=0)\n",
    "\n",
    "# testing yaml file setup\n",
    "config2 = yaml.safe_load(open(\"20220806_two_bunch_FEL_with_kicker_3.yaml\"))\n",
    "data2 = pd.DataFrame(config2['data'])\n",
    "data2.index = map(int, data2.index)\n",
    "data2 = data2.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049ef910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data for x tensor changing MKBs & TDLYs with y tensor being obj_sum\n",
    "# different yaml files will substitute different PVs here\n",
    "xtorch_tensor1 = torch.tensor(data1['MKB:SYS0:3:VAL'].values)\n",
    "xtorch_tensor2 = torch.tensor(data1['MKB:SYS0:4:VAL'].values)\n",
    "xtorch_tensor3 = torch.tensor(data1['TDLY:LI21:1:ADelaySet'].values)\n",
    "xtorch_tensor4 = torch.tensor(data1['TDLY:LI21:1:CDelaySet'].values)\n",
    "\n",
    "xtorch_tensor1 = xtorch_tensor1.reshape(-1,1)\n",
    "xtorch_tensor2 = xtorch_tensor2.reshape(-1,1)\n",
    "xtorch_tensor3 = xtorch_tensor3.reshape(-1,1)\n",
    "xtorch_tensor4 = xtorch_tensor4.reshape(-1,1)\n",
    "xtorch_tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01c2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtorch_tensor = torch.cat( (xtorch_tensor1, xtorch_tensor2, xtorch_tensor3, xtorch_tensor4), dim=1)\n",
    "ytorch_tensor = torch.tensor(data1['obj_sum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1019adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data for x tensor changing MKBs & TDLYs with y tensor being obj_sum\n",
    "# different yaml files will substitute different PVs here\n",
    "x2torch_tensor1 = torch.tensor(data2['MKB:SYS0:3:VAL'].values)\n",
    "x2torch_tensor2 = torch.tensor(data2['MKB:SYS0:4:VAL'].values)\n",
    "x2torch_tensor3 = torch.tensor(data2['TDLY:LI21:1:ADelaySet'].values)\n",
    "x2torch_tensor4 = torch.tensor(data2['TDLY:LI21:1:CDelaySet'].values)\n",
    "\n",
    "x2torch_tensor1 = x2torch_tensor1.reshape(-1,1)\n",
    "x2torch_tensor2 = x2torch_tensor2.reshape(-1,1)\n",
    "x2torch_tensor3 = x2torch_tensor3.reshape(-1,1)\n",
    "x2torch_tensor4 = x2torch_tensor4.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e81a5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_tensor = torch.cat( (x2torch_tensor1, x2torch_tensor2, x2torch_tensor3, x2torch_tensor4), dim=1)\n",
    "ytest_tensor = torch.tensor(data2['obj_sum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3a0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training and testing variables\n",
    "train_x = xtorch_tensor.float()\n",
    "train_y = ytorch_tensor.float().reshape(-1,1) #need to reshape for botorch fit\n",
    "test_x = xtest_tensor.float()\n",
    "test_y = ytest_tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2bfa27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape\n",
    "train_y.shape\n",
    "test_x.shape\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7125699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0].shape\n",
    "ytorch_tensor.shape\n",
    "ytest_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f9cde11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleTaskGP(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): ConstantMean()\n",
       "  (covar_module): ScaleKernel(\n",
       "    (base_kernel): RBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "      (distance_module): Distance()\n",
       "    )\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       "  (outcome_transform): Standardize()\n",
       "  (input_transform): InputStandardize()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[-1]) #ard_num_dims specifies unique lengthscales\n",
    "scaled_covar_module = gpytorch.kernels.ScaleKernel(covar_module)\n",
    "\n",
    "########################################\n",
    "#mean\n",
    "\n",
    "#     constant_constraint = gpytorch.constraints.GreaterThan(50.)\n",
    "#     constant_constraint = gpytorch.constraints.Positive()\n",
    "#     constant_prior = gpytorch.priors.GammaPrior(10,10)\n",
    "constant_constraint = None\n",
    "constant_prior = None\n",
    "mean_module = gpytorch.means.ConstantMean(constant_prior = constant_prior, constant_constraint=constant_constraint)\n",
    "#     mean_module = None\n",
    "########################################\n",
    "#noise/likelihood\n",
    "\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1,10)\n",
    "noise_prior = None\n",
    "noise_constraint = None\n",
    "#     noise_constraint = gpytorch.constraints.GreaterThan(0.01)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior, noise_constraint=noise_constraint)\n",
    "\n",
    "########################################\n",
    "#transforms\n",
    "\n",
    "outcome_transform = Standardize(m=1)\n",
    "input_transform = InputStandardize(d=train_x.shape[-1])  \n",
    "#     input_transform = Normalize(d=train_x.shape[-1])  \n",
    "#     outcome_transform = None\n",
    "#     input_transform = None\n",
    "\n",
    "########################################\n",
    "#model\n",
    "\n",
    "model = SingleTaskGP(train_x, train_y, likelihood, mean_module = mean_module, covar_module = scaled_covar_module, \n",
    "                     outcome_transform = outcome_transform, input_transform = input_transform)\n",
    "\n",
    "########################################\n",
    "# Find optimal model hyperparameters\n",
    "\n",
    "model.train()\n",
    "model.likelihood.train()\n",
    "\n",
    "\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "408ac06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # exact interference GP model     useless and used only in the tutorial\n",
    "# class ExactGPModel(gpytorch.models.ExactGP):\n",
    "#     def __init__(self, train_x, train_y, likelihood):\n",
    "#         super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "#         self.mean_module = gpytorch.means.ConstantMean()\n",
    "#         self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[-1]))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         mean_x = self.mean_module(x)\n",
    "#         covar_x = self.covar_module(x)\n",
    "#         return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# # initialize likelihood and model\n",
    "# likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65fe75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing framework     useless and used only in the tutorial\n",
    "# import os\n",
    "# smoke_test = ('CI' in os.environ)\n",
    "# training_iter = 2 if smoke_test else 50\n",
    "\n",
    "\n",
    "# # Find optimal model hyperparameters\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # Use the adam optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# # \"Loss\" for GPs - the marginal log likelihood\n",
    "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# for i in range(training_iter):\n",
    "#     # Zero gradients from previous iteration\n",
    "#     optimizer.zero_grad()\n",
    "#     # Output from model\n",
    "#     output = model(train_x)\n",
    "#     # Calc loss and backprop gradients\n",
    "#     loss = -mll(output, train_y)\n",
    "#     loss.backward()\n",
    "# #     print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "# #         i + 1, training_iter, loss.item(),\n",
    "# # #         model.covar_module.base_kernel.lengthscale.item(),\n",
    "# #         model.likelihood.noise.item()\n",
    "# #     ))\n",
    "#     optimizer.step()\n",
    "    \n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa18e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[44.5281,  0.0761,  0.6698,  0.8312]], grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.base_kernel.lengthscale #different lengthscales for each input dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b789a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction variables\n",
    "f_preds = model.posterior(train_x) #use model.posterior(x) with botorch\n",
    "# pred_ys = likelihood(model(train_x))\n",
    "\n",
    "f_mean = f_preds.mean\n",
    "f_var = f_preds.variance\n",
    "# f_covar = f_preds.covariance_matrix       these serve no purpose for this task\n",
    "# f_samples = f_preds.sample(sample_shape=torch.Size([1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8947b1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output:         training (true) output:\n",
      "0.006293616723269224 0.006757116410881281\n",
      "0.0030183831695467234 0.0010537994094192982\n",
      "0.0064027197659015656 0.00694710249081254\n",
      "0.005029063206166029 0.004555090330541134\n",
      "0.004540909081697464 0.003704942762851715\n",
      "0.005149630829691887 0.004765040706843138\n",
      "0.015703771263360977 0.019816692918539047\n",
      "0.002330007031559944 -0.00035343770286999643\n",
      "0.003222365165129304 0.0038610671181231737\n",
      "0.0022909059189260006 -0.001639565802179277\n",
      "0.0023368927650153637 0.004391191527247429\n",
      "0.0021777087822556496 0.0018923194147646427\n",
      "0.0038352692499756813 0.0017220921581611037\n",
      "0.008075685240328312 0.012108211405575275\n",
      "0.005125525873154402 0.0034987523686140776\n",
      "0.002487919293344021 0.0003806102031376213\n",
      "0.0029075914062559605 -0.0008408636203967035\n",
      "0.0031361046712845564 0.003399439388886094\n",
      "0.0035965736024081707 0.0019523053197190166\n",
      "0.0070185475051403046 0.0008193397079594433\n",
      "0.012346385978162289 0.01737982966005802\n",
      "0.016507387161254883 0.019311798736453056\n",
      "0.00573879387229681 0.004686185158789158\n",
      "0.004573269281536341 0.003088806988671422\n",
      "0.004560625180602074 0.0040887342765927315\n",
      "0.004648750647902489 0.006533706560730934\n",
      "0.005166397895663977 0.004165132064372301\n",
      "0.004680107347667217 0.0046357400715351105\n",
      "0.0044035529717803 0.0037835168186575174\n",
      "0.004545846022665501 0.004295587074011564\n",
      "0.0081400191411376 0.009852193295955658\n",
      "0.006817802786827087 0.006845616269856691\n",
      "0.006026827730238438 0.006291340105235577\n",
      "0.006503673270344734 0.006369234062731266\n",
      "0.006436843890696764 0.005306457635015249\n",
      "0.008074915036559105 0.0074605257250368595\n",
      "0.008373161777853966 0.0106425192207098\n",
      "0.005810304079204798 0.004274973180145025\n",
      "0.006564661860466003 0.008462199941277504\n",
      "0.006824043113738298 0.008710760623216629\n",
      "0.006551791913807392 0.005712996702641249\n",
      "0.00752272829413414 0.009055519476532936\n",
      "0.007998894900083542 0.004851647187024355\n",
      "0.009381815791130066 0.0023415826726704836\n",
      "0.011889474466443062 0.018313128501176834\n",
      "0.008603728376328945 0.014886962249875069\n",
      "0.008236680179834366 0.0059424941428005695\n",
      "0.01197104062885046 0.011723612435162067\n",
      "0.00754481740295887 0.01105169765651226\n",
      "0.007225063629448414 0.007973415777087212\n",
      "0.0065215835347771645 0.005558893084526062\n",
      "0.006622078362852335 0.01155546959489584\n",
      "0.007835597731173038 0.005612372420728207\n",
      "0.007677655201405287 0.008519813418388367\n",
      "0.007839133962988853 0.005287193693220615\n",
      "0.010760798119008541 0.00929705984890461\n",
      "0.010550634935498238 0.013499176129698753\n"
     ]
    }
   ],
   "source": [
    "print('model output:         training (true) output:')\n",
    "for pred, obs in zip(f_mean.squeeze(), train_y.squeeze()):\n",
    "    print(pred.item(), obs.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c79ed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0600, -0.0181,  0.1083,  0.1113])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish variable for time and plot predicted versus observed obj_sum over time\n",
    "time = torch.tensor(data2['time'].values)\n",
    "time_tensor = time.float()\n",
    "\n",
    "plt.plot(time_tensor, test_y, label=r\"Observed obj_sum\", linestyle=\"dotted\")\n",
    "plt.plot(time_tensor, train_y, label=r\"Predicted obj_sum\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$Model Output$\")\n",
    "plt.ylabel(\"$Iteration$\")\n",
    "_ = plt.title(\"Predicted versus Observed obj_sum over iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs = train_x[0].repeat(100,1)\n",
    "test_xs[:,0] = torch.linspace(torch.min(train_x[:,0]), torch.max(train_x[:,0]), 100) \n",
    "pred_ys = model.posterior(test_xs).mean\n",
    "plt.plot(test_xs[:,0].detach().numpy(), pred_ys.detach().numpy())\n",
    "plt.scatter(train_x[0,0], train_y[0])\n",
    "\n",
    "\n",
    "plt.title('obj_sum vs MKB:SYS0:3:VAL for [MKB:SYS0:4:VAL, TDLY:LI21:1:ADelaySet, TDLY:LI21:1:CDelaySet] = [' + str(train_x[0,1].detach().numpy()) + ', ' + str(train_x[0,2].detach().numpy()) + ', ' + str(train_x[0,3].detach().numpy()) +']' )\n",
    "plt.ylabel('Output')\n",
    "plt.xlabel('MKB:SYS0:3:VAL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ys.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs = train_x[0].repeat(100,1) #duplicate first training point 100 times row-wise\n",
    "test_xs[:,1] = torch.linspace(torch.min(train_x[:,1]), torch.max(train_x[:,1]), 100) #replace first column with a linspace\n",
    "pred_ys = model.posterior(test_xs).mean #evaluate model along a 1d subspace of the 4d space.\n",
    "plt.plot(test_xs[:,1].detach().numpy(), pred_ys.detach().numpy())\n",
    "plt.scatter(train_x[0,1], train_y[0]) #plot the first training point (which lies somewhere in the 1d subspace)\n",
    "\n",
    "plt.title('Posterior Mean vs MKB:SYS0:4:VAL for [MKB:SYS0:3:VAL, TDLY:LI21:1:ADelaySet, TDLY:LI21:1:CDelaySet] = [' + str(train_x[0,0].detach().numpy()) + ', ' + str(train_x[0,2].detach().numpy()) + ', ' + str(train_x[0,3].detach().numpy()) +']' )\n",
    "plt.ylabel('Model Output')\n",
    "plt.xlabel('MKB:SYS0:4:VAL') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3dd915",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ys = model(test_xs).mean\n",
    "plt.plot(test_xs[:,0].detach().numpy(), pred_ys.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(train_x[0,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs = train_x[0].repeat(100,1)\n",
    "test_xs[:,2] = torch.linspace(torch.min(train_x[:,2]), torch.max(train_x[:,2]), 100) \n",
    "pred_ys = model.posterior(test_xs).mean\n",
    "plt.plot(test_xs[:,2].detach().numpy(), pred_ys.detach().numpy())\n",
    "plt.scatter(train_x[0,2], train_y[0])\n",
    "\n",
    "plt.title('Posterior Mean vs TDLY:LI21:1:ADelaySet for [MKB:SYS0:3:VAL, MKB:SYS0:4:VAL, TDLY:LI21:1:CDelaySet] = [' + str(train_x[0,0].detach().numpy()) + ', ' + str(train_x[0,2].detach().numpy()) + ', ' + str(train_x[0,3].detach().numpy()) +']' )\n",
    "plt.ylabel('Model Output')\n",
    "plt.xlabel('TDLY:LI21:1:ADelaySet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs = train_x[0].repeat(100,1)\n",
    "test_xs[:,3] = torch.linspace(torch.min(train_x[:,3]), torch.max(train_x[:,3]), 100) \n",
    "pred_ys = model.posterior(test_xs).mean\n",
    "plt.plot(test_xs[:,3].detach().numpy(), pred_ys.detach().numpy())\n",
    "plt.scatter(train_x[0,3], train_y[0])\n",
    "\n",
    "plt.title('Posterior Mean vs TDLY:LI21:1:CDelaySet for [MKB:SYS0:3:VAL, MKB:SYS0:4:VAL, TDLY:LI21:1:ADelaySet] = [' + str(train_x[0,0].detach().numpy()) + ', ' + str(train_x[0,2].detach().numpy()) + ', ' + str(train_x[0,3].detach().numpy()) +']' )\n",
    "plt.ylabel('Model Output')\n",
    "plt.xlabel('TDLY:LI21:1:CDelaySet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9eec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d55a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the training and testing\n",
    "with torch.no_grad():\n",
    "    # initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd7d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20d34b-5601-422a-b09f-67bc132737ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e54087-e218-4726-9cc7-17bcdf921a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682ff48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ec285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c440b6-4b3d-4b17-b88f-c4ff44fb866a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f26c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8e044-1540-4a46-8808-5b04e8164e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406fce3-ec0d-4332-8793-e385c6407ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f5062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2c092-8bfd-4ab1-9be2-7dbbccbdd649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8695e-a068-433b-828a-265420c4d05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55366951-f8da-43fb-b2b8-f7d0b314f97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f28cbb-0b9a-4108-9b3e-25276c0edcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b864a56-efb1-41a7-9ead-7606fed9b777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a30928-115d-423c-b870-461890b8689e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754496a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4b05d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d49f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2b4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ef83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823c2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f5442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5caad5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a85ce-f13d-4930-b9b0-0a09946627eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346ee7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raftask",
   "language": "python",
   "name": "raftask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
